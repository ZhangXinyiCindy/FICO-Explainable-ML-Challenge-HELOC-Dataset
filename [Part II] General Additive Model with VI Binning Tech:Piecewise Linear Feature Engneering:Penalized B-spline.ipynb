{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAT3612 Statistical Machine Learning (2019-20 Semester 1) <a class=\"tocSkip\">\n",
    "\n",
    "## Assignment 2  <a class=\"tocSkip\">\n",
    "\n",
    "*ZHANG XINYI UID:3035234571*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:16:16.342609Z",
     "start_time": "2019-10-25T15:16:16.332600Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import scorecardpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "# show plots automatically\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer,IterativeImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pygam import LogisticGAM,f,s\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from patsy import dmatrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:16:16.407401Z",
     "start_time": "2019-10-25T15:16:16.344568Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RiskFlag</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>x16</th>\n",
       "      <th>x17</th>\n",
       "      <th>x18</th>\n",
       "      <th>x19</th>\n",
       "      <th>x20</th>\n",
       "      <th>x21</th>\n",
       "      <th>x22</th>\n",
       "      <th>x23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bad</td>\n",
       "      <td>75.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bad</td>\n",
       "      <td>66.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>69.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>75.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bad</td>\n",
       "      <td>63.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  RiskFlag    x1     x2   x3     x4    x5   x6   x7     x8    x9  ...   x14  \\\n",
       "0      Bad  75.0  169.0  2.0   59.0  21.0  0.0  0.0  100.0   NaN  ...  36.0   \n",
       "1      Bad  66.0  502.0  4.0  145.0  34.0  0.0  0.0   97.0  36.0  ...  27.0   \n",
       "2     Good  69.0  338.0  2.0   62.0  22.0  0.0  0.0   96.0  12.0  ...  35.0   \n",
       "3     Good  75.0  422.0  1.0   91.0  55.0  0.0  0.0  100.0   NaN  ...  33.0   \n",
       "4      Bad  63.0  242.0  2.0   68.0  25.0  0.0  0.0  100.0   NaN  ...  19.0   \n",
       "\n",
       "   x15  x16  x17   x18    x19   x20  x21   x22   x23  \n",
       "0  NaN  4.0  4.0  43.0  112.0   4.0  6.0   0.0  83.0  \n",
       "1  4.0  3.0  3.0  80.0   53.0  17.0  3.0  12.0  83.0  \n",
       "2  0.0  4.0  4.0  25.0  100.0   3.0  2.0   1.0  45.0  \n",
       "3  0.0  4.0  4.0   2.0   11.0  12.0  2.0   1.0  57.0  \n",
       "4  NaN  3.0  3.0  73.0    NaN  12.0  1.0   5.0  87.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./HelocData.csv', na_values = [-7, -8, -9])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the variable names and preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:16:16.440314Z",
     "start_time": "2019-10-25T15:16:16.409395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variable Names</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>Consolidated version of risk markers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>Months Since Oldest Trade Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>Months Since Most Recent Trade Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>Average Months in File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x5</th>\n",
       "      <td>Number Satisfactory Trades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x6</th>\n",
       "      <td>Number Trades 60+ Ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x7</th>\n",
       "      <td>Number Trades 90+ Ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x8</th>\n",
       "      <td>Percent Trades Never Delinquent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x9</th>\n",
       "      <td>Months Since Most Recent Delinquency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x10</th>\n",
       "      <td>Max Delq/Public Records Last 12 Months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x11</th>\n",
       "      <td>Max Delinquency Ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x12</th>\n",
       "      <td>Number of Total Trades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x13</th>\n",
       "      <td>Number of Trades Open in Last 12 Months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x14</th>\n",
       "      <td>Percent Installment Trades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x15</th>\n",
       "      <td>Months Since Most Recent Inq excl 7days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x16</th>\n",
       "      <td>Number of Inq Last 6 Months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x17</th>\n",
       "      <td>Number of Inq Last 6 Months excl 7days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x18</th>\n",
       "      <td>Net Fraction Revolving Burden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x19</th>\n",
       "      <td>Net Fraction Installment Burden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x20</th>\n",
       "      <td>Number Revolving Trades with Balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x21</th>\n",
       "      <td>Number Installment Trades with Balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x22</th>\n",
       "      <td>Number Bank/Natl Trades w high utilization ratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x23</th>\n",
       "      <td>Percent Trades with Balance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Description\n",
       "Variable Names                                                  \n",
       "x1                          Consolidated version of risk markers\n",
       "x2                                Months Since Oldest Trade Open\n",
       "x3                           Months Since Most Recent Trade Open\n",
       "x4                                        Average Months in File\n",
       "x5                                    Number Satisfactory Trades\n",
       "x6                                        Number Trades 60+ Ever\n",
       "x7                                        Number Trades 90+ Ever\n",
       "x8                               Percent Trades Never Delinquent\n",
       "x9                          Months Since Most Recent Delinquency\n",
       "x10                       Max Delq/Public Records Last 12 Months\n",
       "x11                                         Max Delinquency Ever\n",
       "x12                                       Number of Total Trades\n",
       "x13                      Number of Trades Open in Last 12 Months\n",
       "x14                                   Percent Installment Trades\n",
       "x15                      Months Since Most Recent Inq excl 7days\n",
       "x16                                  Number of Inq Last 6 Months\n",
       "x17                       Number of Inq Last 6 Months excl 7days\n",
       "x18                                Net Fraction Revolving Burden\n",
       "x19                              Net Fraction Installment Burden\n",
       "x20                         Number Revolving Trades with Balance\n",
       "x21                       Number Installment Trades with Balance\n",
       "x22             Number Bank/Natl Trades w high utilization ratio\n",
       "x23                                  Percent Trades with Balance"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = pd.read_excel('./HelocDataDict.xlsx', index_col=0, squeeze=True)\n",
    "var_names = data_dict.str.split('(\\.| \\()', expand=True).iloc[1:,0] # only select the first part\n",
    "var_names.name = 'Description'\n",
    "\n",
    "var_names.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set preparation\n",
    "\n",
    "#### 1) Split the data into training and testing sets with UID as the random seed\n",
    "#### 2) Convert Risk Flag column to \"0\" and \"1\"\n",
    "#### 3) Use Iterative Imputer to handle missing value\n",
    "#### 4) Drop variables not interested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:16:16.743501Z",
     "start_time": "2019-10-25T15:16:16.732532Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of training set: 0.80%\n",
      "Proportion of training set: 0.20%\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets with UID as the random seed\n",
    "np.random.seed(3035234571) \n",
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "train_size = df_train.shape[0]/df.shape[0]\n",
    "test_size = df_test.shape[0]/df.shape[0]\n",
    "print('Proportion of training set: {:.2f}%'.format(train_size))\n",
    "print('Proportion of training set: {:.2f}%'.format(test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling missing value and drop unrelated columns\n",
    "def df_preprocesser(df, II=None,set='train'):\n",
    "    df_tmp = df.copy()\n",
    "    # use Iterative Imputer for imputation\n",
    "    label_encoder = LabelEncoder()\n",
    "    df_tmp['RiskFlag'] = label_encoder.fit_transform(df_tmp['RiskFlag'])\n",
    "\n",
    "    if set=='train':\n",
    "        II = IterativeImputer().fit(df_tmp)\n",
    "    df_tmp[:] = II.transform(df_tmp)\n",
    "    \n",
    "    #drop unrelated columns\n",
    "    names = ['RiskFlag','x1', 'x5', 'x16', 'x17', 'x20']\n",
    "    df_tmp = df_tmp[names]\n",
    "\n",
    "    return df_tmp, II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangxinyi/anaconda3/lib/python3.7/site-packages/sklearn/impute/_iterative.py:599: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#3) Use training data set to fit Iterative Imputer and pass the fitted imputer to testing data.\n",
    "df_train_clean, II= df_preprocesser(df_train, set='train')\n",
    "df_test_clean= df_preprocesser(df_test,II, set='test')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RiskFlag</th>\n",
       "      <th>x1</th>\n",
       "      <th>x5</th>\n",
       "      <th>x16</th>\n",
       "      <th>x17</th>\n",
       "      <th>x20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6288</th>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>1.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10108</th>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5134</th>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RiskFlag    x1    x5  x16  x17   x20\n",
       "6288        0.0  61.0  26.0  0.0  0.0   7.0\n",
       "1771        1.0  66.0  33.0  4.0  4.0   2.0\n",
       "2706        0.0  72.0  56.0  1.0  1.0  12.0\n",
       "10108       1.0  75.0   7.0  0.0  0.0   2.0\n",
       "5134        0.0  67.0  31.0  3.0  3.0   6.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After handling missing value and drop unrelated variables, the data frame looks like:\n",
    "df_train_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "#### 1)Transform data set with the IV binning technique for each selected feature. \n",
    " Use training data to fit the woebin and apply the fitted break knots on testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_IVBinning(df, x1_breaks=None, x5_breaks=None,x16_breaks=None,\n",
    "                     x17_breaks=None,x20_breaks=None,set='train'):\n",
    "    df_tmp = df.copy()\n",
    "    # use IV binning\n",
    "    if set=='train':\n",
    "        x_bins = sc.woebin(df_tmp, y='RiskFlag', method='tree')\n",
    "        x1_breaks = np.insert(x_bins['x1']['breaks'].values.astype(np.float), 0, -np.inf)\n",
    "        x5_breaks = np.insert(x_bins['x5']['breaks'].values.astype(np.float), 0, -np.inf)\n",
    "        x16_breaks = np.insert(x_bins['x16']['breaks'].values.astype(np.float), 0, -np.inf)\n",
    "        x17_breaks = np.insert(x_bins['x17']['breaks'].values.astype(np.float), 0, -np.inf)\n",
    "        x20_breaks = np.insert(x_bins['x20']['breaks'].values.astype(np.float), 0, -np.inf)\n",
    "\n",
    "    df_tmp['x1'] = pd.cut(df_tmp['x1'], bins=x1_breaks, right=True)\n",
    "    df_tmp['x5'] = pd.cut(df_tmp['x5'], bins=x5_breaks, right=True)\n",
    "    df_tmp['x16'] = pd.cut(df_tmp['x16'], bins=x16_breaks, right=True)\n",
    "    df_tmp['x17'] = pd.cut(df_tmp['x17'], bins=x17_breaks, right=True)\n",
    "    df_tmp['x20'] = pd.cut(df_tmp['x20'], bins=x1_breaks, right=True)\n",
    "    df_tmp\n",
    "    \n",
    "    # one-hot encoding\n",
    "    df_tmp = pd.get_dummies(df_tmp, columns=['x1','x5','x16','x17','x20'], drop_first=True)\n",
    "\n",
    "    return df_tmp, x1_breaks, x5_breaks, x16_breaks, x17_breaks, x20_breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating woe binning ...\n"
     ]
    }
   ],
   "source": [
    "#Use training data to fit the woebin and apply the fitted break knots on testing data\n",
    "df_train_IVBinning, x1_breaks, x5_breaks, x16_breaks, x17_breaks, x20_breaks= df_IVBinning(df_train_clean, set='train')\n",
    "df_test_IVBinning= df_IVBinning(df_test_clean,x1_breaks, x5_breaks, x16_breaks, x17_breaks, x20_breaks, set='test')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RiskFlag</th>\n",
       "      <th>x1_(69.0, 75.0]</th>\n",
       "      <th>x1_(75.0, 84.0]</th>\n",
       "      <th>x1_(84.0, inf]</th>\n",
       "      <th>x5_(6.0, 12.0]</th>\n",
       "      <th>x5_(12.0, 19.0]</th>\n",
       "      <th>x5_(19.0, 20.0]</th>\n",
       "      <th>x5_(20.0, inf]</th>\n",
       "      <th>x16_(1.0, 2.0]</th>\n",
       "      <th>x16_(2.0, 4.0]</th>\n",
       "      <th>x16_(4.0, inf]</th>\n",
       "      <th>x17_(1.0, 2.0]</th>\n",
       "      <th>x17_(2.0, 4.0]</th>\n",
       "      <th>x17_(4.0, inf]</th>\n",
       "      <th>x20_(69.0, 75.0]</th>\n",
       "      <th>x20_(75.0, 84.0]</th>\n",
       "      <th>x20_(84.0, inf]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6288</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10108</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5134</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RiskFlag  x1_(69.0, 75.0]  x1_(75.0, 84.0]  x1_(84.0, inf]  \\\n",
       "6288        0.0                0                0               0   \n",
       "1771        1.0                0                0               0   \n",
       "2706        0.0                1                0               0   \n",
       "10108       1.0                1                0               0   \n",
       "5134        0.0                0                0               0   \n",
       "\n",
       "       x5_(6.0, 12.0]  x5_(12.0, 19.0]  x5_(19.0, 20.0]  x5_(20.0, inf]  \\\n",
       "6288                0                0                0               1   \n",
       "1771                0                0                0               1   \n",
       "2706                0                0                0               1   \n",
       "10108               1                0                0               0   \n",
       "5134                0                0                0               1   \n",
       "\n",
       "       x16_(1.0, 2.0]  x16_(2.0, 4.0]  x16_(4.0, inf]  x17_(1.0, 2.0]  \\\n",
       "6288                0               0               0               0   \n",
       "1771                0               1               0               0   \n",
       "2706                0               0               0               0   \n",
       "10108               0               0               0               0   \n",
       "5134                0               1               0               0   \n",
       "\n",
       "       x17_(2.0, 4.0]  x17_(4.0, inf]  x20_(69.0, 75.0]  x20_(75.0, 84.0]  \\\n",
       "6288                0               0                 0                 0   \n",
       "1771                1               0                 0                 0   \n",
       "2706                0               0                 0                 0   \n",
       "10108               0               0                 0                 0   \n",
       "5134                1               0                 0                 0   \n",
       "\n",
       "       x20_(84.0, inf]  \n",
       "6288                 0  \n",
       "1771                 0  \n",
       "2706                 0  \n",
       "10108                0  \n",
       "5134                 0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After transforming for IV binning method, the data frame looks like:\n",
    "df_train_IVBinning.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "#### 2)Train the generalized additive model with IV binning technique \n",
    " The variables are all categorical after IV binning transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (11 of 11) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set for GAM with IV Binning = 0.7332\n",
      "Accuracy on the test set for GAM with IV Binning = 0.7357\n"
     ]
    }
   ],
   "source": [
    "x_train_IV = df_train_IVBinning.iloc[:,1:].values\n",
    "y_train_IV = df_train_IVBinning.iloc[:,0].values\n",
    "\n",
    "x_test_IV = df_test_IVBinning.iloc[:,1:].values\n",
    "y_test_IV = df_test_IVBinning.iloc[:,0].values\n",
    "\n",
    "from pygam import LogisticGAM,f,s\n",
    "\n",
    "gam = LogisticGAM(f(0)+f(1)+f(2)+f(3)+f(4)+f(5)+f(6)+f(7)+f(8)+f(9)+f(10)+f(11)+f(12)+f(13)+f(14)+f(15))\n",
    "# f: factor term\n",
    "# some parameters combinations in grid search meet the error exception.\n",
    "gam.gridsearch(x_train_IV,y_train_IV)\n",
    "\n",
    "                  \n",
    "y_pred_train_IV = gam.predict(x_train_IV)\n",
    "y_pred_test_IV = gam.predict(x_test_IV)\n",
    "\n",
    "# accuracy score\n",
    "accuracy_train_IV = accuracy_score(y_train_IV, y_pred_train_IV)\n",
    "accuracy_test_IV = accuracy_score(y_test_IV, y_pred_test_IV)\n",
    "print('Accuracy on the training set for GAM with IV Binning =', np.round(accuracy_train_IV,4))\n",
    "print('Accuracy on the test set for GAM with IV Binning =', np.round(accuracy_test_IV,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "#### Re-train the generalized additive model in question 1 with the piecewise-linear feature engineering.\n",
    "Use the pygam package, by setting the spline order equal to 1, p-spline model's basis function becomes piecewise-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (11 of 11) |########################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set for GAM with piecewise-linear feature engineering =  0.7386\n",
      "Accuracy on the test set for GAM with piecewise-linear feature engineering =  0.7404\n"
     ]
    }
   ],
   "source": [
    "x_train_PL = df_train_clean.iloc[:,1:].values\n",
    "y_train_PL = df_train_clean.iloc[:,0].values\n",
    "\n",
    "x_test_PL = df_test_clean.iloc[:,1:].values\n",
    "y_test_PL = df_test_clean.iloc[:,0].values\n",
    "\n",
    "x_train_PL = x_train_PL.reshape([-1,5])\n",
    "n_splines=10\n",
    "\n",
    "\n",
    "    \n",
    "    # build P-spline, set spline_order to 1 so the basis function is piecewise linear\n",
    "p_spl_PL = LogisticGAM(s(0, n_splines=n_splines,spline_order=1)\\\n",
    "                  +s(1, n_splines=n_splines, spline_order=1)\\\n",
    "                  +s(2, n_splines=n_splines, spline_order=1)\\\n",
    "                  +s(3, n_splines=n_splines, spline_order=1)\\\n",
    "                  +s(4, n_splines=n_splines, spline_order=1))\n",
    "    #\"0\" the first explainatory variable(index of feature); n_spines df(dim of ); derivative specify the penalty\n",
    "p_spl_PL.gridsearch(x_train_PL, y_train_PL) \n",
    "    #help you automatically pick lumda\n",
    "    \n",
    "    # predict\n",
    "y_pred_train_PL = p_spl_PL.predict(x_train_PL)\n",
    "y_pred_test_PL = p_spl_PL.predict(x_test_PL)\n",
    "\n",
    "# accuracy score\n",
    "accuracy_train_PL = accuracy_score(y_train_PL, y_pred_train_PL)\n",
    "accuracy_test_PL = accuracy_score(y_test_PL, y_pred_test_PL)\n",
    "\n",
    "print('Accuracy on the training set for GAM with piecewise-linear feature engineering = ', np.round(accuracy_train_PL,4))\n",
    "print('Accuracy on the test set for GAM with piecewise-linear feature engineering = ', np.round(accuracy_test_PL,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "#### Re-train the generalized additive model in question 1 with penalized B-splines .\n",
    "Use the pygam package, by setting the spline order equal to 3, fit the p-spline model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (11 of 11) |########################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set for GAM with penalized B-splines  = 0.7373\n",
      "Accuracy on the test set for GAM with penalized B-splines  = 0.7409\n"
     ]
    }
   ],
   "source": [
    "x_train_BS = df_train_clean.iloc[:,1:].values\n",
    "y_train_BS = df_train_clean.iloc[:,0].values\n",
    "\n",
    "x_test_BS = df_test_clean.iloc[:,1:].values\n",
    "y_test_BS = df_test_clean.iloc[:,0].values\n",
    "\n",
    "x_train_BS = x_train_BS.reshape([-1,5])\n",
    "n_splines=8\n",
    "spline_order=3\n",
    "\n",
    "    \n",
    "    # build P-spline\n",
    "p_spl = LogisticGAM(s(0, n_splines=n_splines,spline_order=spline_order, penalties='derivative')\\\n",
    "                  +s(1, n_splines=n_splines,spline_order=spline_order, penalties='derivative')\\\n",
    "                  +s(2, n_splines=n_splines,spline_order=spline_order, penalties='derivative')\\\n",
    "                  +s(3, n_splines=n_splines,spline_order=spline_order, penalties='derivative')\\\n",
    "                  +s(4, n_splines=n_splines,spline_order=spline_order, penalties='derivative'))\n",
    "    #\"0\" the first explainatory variable(index of feature); n_spines df(dim of ); derivative specify the penalty\n",
    "p_spl.gridsearch(x_train_BS, y_train_BS) \n",
    "    #help you automatically pick lumda\n",
    "    \n",
    "    # predict\n",
    "y_pred_train_BS = p_spl.predict(x_train_BS)\n",
    "y_pred_test_BS = p_spl.predict(x_test_BS)\n",
    "\n",
    "# accuracy score\n",
    "accuracy_train_BS = accuracy_score(y_train_BS, y_pred_train_BS)\n",
    "accuracy_test_BS = accuracy_score(y_test_BS, y_pred_test_BS)\n",
    "\n",
    "print('Accuracy on the training set for GAM with penalized B-splines  =', np.round(accuracy_train_BS,4))\n",
    "print('Accuracy on the test set for GAM with penalized B-splines  =', np.round(accuracy_test_BS,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "#### Evaluate their model performance on the testing data and report the prediction accuracy. \n",
    "\n",
    "Prediction accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set for GAM with IV Binning = 0.7357\n",
      "Accuracy on the test set for GAM with piecewise-linear feature engineering =  0.7404\n",
      "Accuracy on the test set for GAM with penalized B-splines  = 0.7409\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on the test set for GAM with IV Binning =', np.round(accuracy_test_IV,4))\n",
    "print('Accuracy on the test set for GAM with piecewise-linear feature engineering = ', np.round(accuracy_test_PL,4))\n",
    "print('Accuracy on the test set for GAM with penalized B-splines  =', np.round(accuracy_test_BS,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the models in (1), (2) and (3) in terms of model explainability. \n",
    "The prediction accuracy increases from 0.7357 to 0.7409 as the model grows more complicated.\n",
    "However, the model explainability decreased during the process.\n",
    "\n",
    "For the first model, GAM with IV Binning technology, it can be interpreted as how the predicted value will change if a variable falls within a certain range.\n",
    "\n",
    "For GAM with piecewise-linear feature engineering and GAM with penalized B-splines (degree=3), it become harder for interpretation. Especially for penalized B-splines (degree=3), the non-linearity of basis function makes the model's overall much less explainable.\n",
    "\n",
    "\n",
    "#### Draw your conclusions about the final model recommendation.\n",
    "\n",
    "I would suggest the second model:  GAM with piecewise-linear feature engineering.\n",
    "The prediction accuracy is a little bit too low for the first model compared to the other two models. \n",
    "GAM with piecewise-linear feature engineering model has only slightly lower prediction accuracy than the third one, but is much more explainable than GAM with penalized B-splines (degree=3). \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
